{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77961305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c59324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5230cdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6796064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec6592",
   "metadata": {},
   "source": [
    "### Experiment-1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fded4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b73d1a",
   "metadata": {},
   "source": [
    "### Experiment-2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d38db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       270\n",
      "           1       0.95      0.70      0.81        30\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.96      0.85      0.89       300\n",
      "weighted avg       0.97      0.97      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1303bc4",
   "metadata": {},
   "source": [
    "### Experiment-3: Train XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee95aa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3084d8c",
   "metadata": {},
   "source": [
    "### Experiment 4: Handle class imbalance using SMOTETomek and then Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe9241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imblearn in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a411c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a84e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       270\n",
      "           1       0.81      0.83      0.82        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.89      0.91      0.90       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec2782",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7a4f3",
   "metadata": {},
   "source": [
    "### Track Experiment Using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288488e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30fa9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f3038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2b27c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.13.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting dagshub\n",
      "  Downloading dagshub-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: PyYAML>=5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (6.0.2)\n",
      "Collecting appdirs>=1.4.4 (from dagshub)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click>=8.0.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (8.1.8)\n",
      "Collecting httpx>=0.23.0 (from dagshub)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: GitPython>=3.1.29 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (3.1.44)\n",
      "Requirement already satisfied: rich>=13.1.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (13.9.4)\n",
      "Collecting dacite~=1.6.0 (from dagshub)\n",
      "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (9.0.0)\n",
      "Collecting gql[requests] (from dagshub)\n",
      "  Downloading gql-4.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dataclasses-json (from dagshub)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (2.0.3)\n",
      "Collecting treelib>=1.6.4 (from dagshub)\n",
      "  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pathvalidate>=3.0.0 (from dagshub)\n",
      "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub) (2.9.0.post0)\n",
      "Collecting boto3 (from dagshub)\n",
      "  Downloading boto3-1.37.38-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting semver (from dagshub)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n",
      "  Downloading dagshub_annotation_converter-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from click>=8.0.4->dagshub) (0.4.6)\n",
      "Collecting lxml (from dagshub-annotation-converter>=0.1.5->dagshub)\n",
      "  Downloading lxml-6.0.0-cp38-cp38-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (10.4.0)\n",
      "Collecting pydantic>=2.0.0 (from dagshub-annotation-converter>=0.1.5->dagshub)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\n",
      "Collecting anyio (from httpx>=0.23.0->dagshub)\n",
      "  Using cached anyio-4.5.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from httpx>=0.23.0->dagshub) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->dagshub)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from httpx>=0.23.0->dagshub) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->dagshub)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from rich>=13.1.0->dagshub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from rich>=13.1.0->dagshub) (2.19.1)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from treelib>=1.6.4->dagshub) (1.17.0)\n",
      "Collecting botocore<1.38.0,>=1.37.38 (from boto3->dagshub)\n",
      "  Downloading botocore-1.37.38-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->dagshub)\n",
      "  Downloading s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from gql[requests]->dagshub) (3.2.6)\n",
      "Collecting yarl<2.0,>=1.6 (from gql[requests]->dagshub)\n",
      "  Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests<3,>=2.26 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from gql[requests]->dagshub) (2.32.3)\n",
      "Collecting requests_toolbelt<2,>=1.0.0 (from gql[requests]->dagshub)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from pandas->dagshub) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from pandas->dagshub) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from pandas->dagshub) (1.24.3)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.23.0->dagshub)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.23.0->dagshub)\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.38.0,>=1.37.38->boto3->dagshub)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (24.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub)\n",
      "  Downloading pydantic_core-2.27.2-cp38-cp38-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting multidict>=4.0 (from yarl<2.0,>=1.6->gql[requests]->dagshub)\n",
      "  Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.6->gql[requests]->dagshub)\n",
      "  Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading dagshub-0.5.10-py3-none-any.whl (260 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading dagshub_annotation_converter-0.1.12-py3-none-any.whl (35 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading treelib-1.8.0-py3-none-any.whl (30 kB)\n",
      "Downloading boto3-1.37.38-py3-none-any.whl (139 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading anyio-4.5.2-py3-none-any.whl (89 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 5.8/13.5 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 21.7 MB/s eta 0:00:00\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.15.2-cp38-cp38-win_amd64.whl (84 kB)\n",
      "Downloading gql-4.0.0-py3-none-any.whl (89 kB)\n",
      "Downloading lxml-6.0.0-cp38-cp38-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading multidict-6.1.0-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.2.0-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Installing collected packages: appdirs, urllib3, treelib, sniffio, semver, pydantic-core, propcache, pathvalidate, mypy-extensions, multidict, marshmallow, lxml, jmespath, h11, exceptiongroup, dacite, backoff, annotated-types, yarl, typing-inspect, pydantic, httpcore, botocore, anyio, s3transfer, requests_toolbelt, httpx, gql, dataclasses-json, dagshub-annotation-converter, boto3, dagshub\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.5.2 appdirs-1.4.4 backoff-2.2.1 boto3-1.37.38 botocore-1.37.38 dacite-1.6.0 dagshub-0.5.10 dagshub-annotation-converter-0.1.12 dataclasses-json-0.6.7 exceptiongroup-1.3.0 gql-4.0.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jmespath-1.0.1 lxml-6.0.0 marshmallow-3.22.0 multidict-6.1.0 mypy-extensions-1.1.0 pathvalidate-3.2.1 propcache-0.2.0 pydantic-2.10.6 pydantic-core-2.27.2 requests_toolbelt-1.0.0 s3transfer-0.11.5 semver-3.0.4 sniffio-1.3.1 treelib-1.8.0 typing-inspect-0.9.0 urllib3-1.26.20 yarl-1.15.2\n"
     ]
    }
   ],
   "source": [
    "! pip install dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f3e4943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=14658415-7d01-44ac-980d-657b604ea154&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=d91c4e51418d3b1f76dffdda85446d2aaaf6dcef053ed0b9541689182765a4b0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Kahkashan2708\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Kahkashan2708\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Kahkashan2708/MLflow-DagsHub\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Kahkashan2708/MLflow-DagsHub\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Kahkashan2708/MLflow-DagsHub initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Kahkashan2708/MLflow-DagsHub initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Kahkashan2708', repo_name='MLflow-DagsHub', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69cb3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:44:43 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection Experiment' does not exist. Creating a new experiment.\n",
      "2025/08/19 11:45:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/19 11:45:12 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic Regression at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0/runs/7ca05a71a70c484cbd36fad7c3acbac3.\n",
      "2025/08/19 11:45:12 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0.\n",
      "2025/08/19 11:45:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/19 11:45:25 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0/runs/57ced6f219f846abb7edbb38b719f278.\n",
      "2025/08/19 11:45:25 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0.\n",
      "2025/08/19 11:45:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/19 11:45:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0/runs/4c6bb1e17c514ef196ae4c16cc30486c.\n",
      "2025/08/19 11:45:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0.\n",
      "2025/08/19 11:45:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/08/19 11:46:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier With SMOTE at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0/runs/1364825f5aff46008413bf869a3f8a58.\n",
      "2025/08/19 11:46:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Anomaly Detection Experiment\")\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Kahkashan2708/MLflow-DagsHub.mlflow\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "        mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])        \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc11528",
   "metadata": {},
   "source": [
    "### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43c3b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB-Smote' already exists. Creating a new version of this model...\n",
      "2025/08/19 10:26:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB-Smote, version 3\n",
      "Created version '3' of model 'XGB-Smote'.\n"
     ]
    }
   ],
   "source": [
    "model_name=\"XGB-Smote\"\n",
    "run_id=input(\"Enter the Run ID: \")\n",
    "model_uri=f\"runs:/{run_id}/{model_name}\"\n",
    "\n",
    "result=mlflow.register_model(\n",
    "    model_uri, model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107a731",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1226fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8bacb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_uri = \"runs:/405955c868dc4d1d82d7376b857207b7/model\"\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02f187",
   "metadata": {},
   "source": [
    "### Dev Environment --> Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eceb0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'anomaly-detection-prod'.\n",
      "Copied version '3' of model 'XGB-Smote' to version '1' of model 'anomaly-detection-prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1755580657195, current_stage='None', description='', last_updated_timestamp=1755580657195, name='anomaly-detection-prod', run_id='405955c868dc4d1d82d7376b857207b7', run_link='', source='models:/XGB-Smote/3', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Define source and destination\n",
    "dev_model_uri = f\"models:/{model_name}@challenger\"\n",
    "prod_model = \"anomaly-detection-prod\"\n",
    "\n",
    "# Create MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Copy model version\n",
    "client.copy_model_version(\n",
    "    src_model_uri=dev_model_uri,\n",
    "    dst_name=prod_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63172f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_uri = \"runs:/405955c868dc4d1d82d7376b857207b7/model\"\n",
    "# Load model\n",
    "champion_model = mlflow.xgboost.load_model(model_uri)\n",
    "\n",
    "y_pred = champion_model.predict(X_test)\n",
    "print(y_pred[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
